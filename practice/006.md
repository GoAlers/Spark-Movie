

需求

1. 分析不同类型的电影总数 输出格式:(类型,数量)

```
(War,143)
(Fantasy,68)
(Western,68)
(Musical,114)
(Horror,343)
(Crime,211)
(Animation,105)
(Thriller,492)
(Adventure,283)
(Action,503)
```


```
package com.movie

import org.apache.log4j.{Level, Logger}
import org.apache.spark.{SparkConf, SparkContext}

object MovieDemo06 {

  def main(args: Array[String]): Unit = {

    // 原始数据说明
    /**
     * 电影点评系统用户行为分析：用户观看电影和点评电影的所有行为数据的采集、过滤、处理和展示：
     * 1，"ratings.dat"：UserID::MovieID::Rating::Timestamp
     * 2，"users.dat"：UserID::Gender::Age::OccupationID::Zip-code
     * 3，"movies.dat"：MovieID::Title::Genres
     * 4, "occupations.dat"：OccupationID::OccupationName
     */
    // 需求 6:分析不同类型的电影总数
    // 输出格式:(类型,数量)

    // 设置日志级别
    Logger.getLogger("org").setLevel(Level.ERROR) //配置日志

    // spark conf
    val masterUrl = "local[*]"
    val appName = "movie analysis"

    val conf = new SparkConf().setMaster(masterUrl).setAppName(appName)
    val sc = new SparkContext(conf)

    val filepath = "src/main/java/com/movie/data/"
    val moviesRDD = sc.textFile(filepath + "movies.dat")

    // "movies.dat"：MovieID::Title::Genres
    // 切分 [Animation,Children's,Comedy]
    // flatMapValues -> [x,y,z]
    //  => (1,Animation), (1,Children's), (1,Comedy)
    //  => (类型名，数量1)  (Animation,1), (Children's,1), (Comedy,1)
    //  结果
    val moviesInfo = moviesRDD
      .map(x => x.split("::")).map {
      x => {
        (x(0), x(2))
      }
      // (编号,类型) => (1, Animation|Children's|Comedy)
    }.flatMapValues(x => {
      x.split("\\|")
    }).map(x => (x._2, 1))
      .reduceByKey((x, y) => x + y)

    moviesInfo.take(10).foreach(println)

    sc.stop()
  }
}

```
